% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenize.R
\name{.mp_tokenize_word_lookup}
\alias{.mp_tokenize_word_lookup}
\title{Tokenize a Word Including Lookup}
\usage{
.mp_tokenize_word_lookup(word, vocab, lookup, unk_token, max_chars)
}
\arguments{
\item{word}{Character scalar; word to tokenize.}

\item{vocab}{Named integer vector containing vocabulary words. Should have
"vocab_split" attribute, with components named "prefixes", "words",
"suffixes".}

\item{lookup}{A morphemepiece lookup table.}

\item{unk_token}{Token to represent unknown words.}

\item{max_chars}{Maximum length of word recognized.}
}
\value{
Input word, broken into tokens.
}
\description{
Look up a word in the table; go to fall-back otherwise.
}
\keyword{internal}
